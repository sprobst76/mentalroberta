# Base model for tokenizer and model loading (Hugging Face identifier or local path)
MENTALROBERTA_BASE_MODEL=deepset/gbert-base

# Default inference backend for Streamlit demo: "onnx" (CPU) or "pytorch"
MENTALROBERTA_BACKEND=onnx

# Optional shared access token (single value). Leave empty to disable gating.
#MENTALROBERTA_APP_TOKEN=

# Optional multiple access codes with labels, format: name1:code1,name2:code2
#MENTALROBERTA_ACCESS_CODES=alice:abc123,bob:def456

# Optional usage log file path (appends JSON lines with timestamp/session/backend/etc.)
MENTALROBERTA_USAGE_LOG=checkpoints/usage.log

# ONNX model URL for browser usage (not used in current UI; server ONNX is default)
MENTALROBERTA_BROWSER_ONNX_URL=/static/model.onnx

# Tokenizer model for browser (if different from base model and available via Xenova)
#MENTALROBERTA_BROWSER_TOKENIZER=Xenova/bert-base-multilingual-cased
